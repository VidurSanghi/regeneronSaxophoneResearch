# -*- coding: utf-8 -*-
"""Vidur-Regeneron Research Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qSuzY1oulKW3b9lJ4Fxd1XskwtBrx69q
"""

#Simple code to perform feature set analysis, and neural network model training ...

from google.colab import drive
import os
import numpy as np
import librosa
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt

# Mount Google Drive
drive.mount('/content/drive')

# Define directories
training_dir = '/content/drive/MyDrive/physicsToneData/Old/voiceMemos/Regenron Research Data/Training and Dev Set'
test_dir = '/content/drive/MyDrive/physicsToneData/Old/voiceMemos/Regenron Research Data/Test Set'

# Function to extract audio features
def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=None, duration=4)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    rms = librosa.feature.rms(y=y)
    return np.mean(mfccs, axis=1), np.mean(rms, axis=1)

# Lists to store features and labels
mfcc_features, rms_features = [], []
performer_labels = []

# Extract features and labels for the training data
for file in os.listdir(training_dir):
    if file.endswith(".wav"):
        file_path = os.path.join(training_dir, file)
        mfcc, rms = extract_features(file_path)
        mfcc_features.append(mfcc)
        rms_features.append(rms)

        # Extract performer labels from the file name
        performer_label = file.split('_')[2]
        performer_labels.append(performer_label)

# Convert lists to NumPy arrays
mfcc_features = np.array(mfcc_features)
rms_features = np.array(rms_features)
performer_labels = np.array(performer_labels)

# Encode the performer labels
label_encoder = LabelEncoder()
performer_labels_encoded = label_encoder.fit_transform(performer_labels)

# Combine MFCC and RMS features
combined_features = np.concatenate((mfcc_features, rms_features), axis=1)

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(combined_features, performer_labels_encoded, test_size=0.2, random_state=42)

# Build the neural network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(combined_features.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))

# Plot training history
plt.figure(figsize=(10, 6))
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot histograms to visualize the correlation of features
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.hist(mfcc_features.flatten(), bins=20, color='blue', alpha=0.7)
plt.title('MFCC Features')
plt.xlabel('Values')
plt.ylabel('Frequency')

plt.subplot(1, 2, 2)
plt.hist(rms_features.flatten(), bins=20, color='red', alpha=0.7)
plt.title('RMS Features')
plt.xlabel('Values')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# Load test data for evaluation
test_mfcc, test_rms = [], []

for file in os.listdir(test_dir):
    if file.endswith(".wav"):
        file_path = os.path.join(test_dir, file)
        mfcc, rms = extract_features(file_path)
        test_mfcc.append(mfcc)
        test_rms.append(rms)

test_mfcc = np.array(test_mfcc)
test_rms = np.array(test_rms)
test_combined_features = np.concatenate((test_mfcc, test_rms), axis=1)

# Evaluate the model on the test set
test_labels = model.predict(test_combined_features)


# Evaluate and display the model accuracy
# This will require loading the ground truth labels for the test set for proper evaluation

# Assuming test_ground_truth_labels is the ground truth labels for the test set
# Update this line with the actual test ground truth labels

# Load file names from the test set
test_file_names = os.listdir(test_dir)

# Initialize the test_ground_truth_labels list
test_ground_truth_labels = []

# Check file names for the string "Professional" and assign labels accordingly
for file_name in test_file_names:

    if "Professional" in file_name:  # Check for the string "Professional"
        test_ground_truth_labels.append(1)  # Set label 1 for Professional
    else:
        test_ground_truth_labels.append(0)  # Set label 0 for non-Professional

# Perform a thresholding to map the continuous predictions to discrete labels
threshold = 0.5
predicted_labels = (test_labels > threshold).astype(int)

# Calculate the accuracy
accuracy = np.mean(predicted_labels.flatten() == test_ground_truth_labels)
print(f"Test Set Accuracy: {accuracy}")
